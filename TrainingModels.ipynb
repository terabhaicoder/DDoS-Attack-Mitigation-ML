{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c565d2c6-3724-4462-9540-9c8330916a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "###### RANDOM FOREST ######\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "file_path = 'your_output_file_features_with_label.csv'\n",
    "\n",
    "# Read CSV in chunks\n",
    "chunk_size = 100000  \n",
    "\n",
    "# Read CSV in chunks with low_memory=False\n",
    "chunks = pd.read_csv(file_path, chunksize=chunk_size, low_memory=False)\n",
    "\n",
    "# Initialize an empty DataFrame to store concatenated chunks\n",
    "df = pd.DataFrame()\n",
    "for chunk in chunks:\n",
    "    df = pd.concat([df, chunk])\n",
    "\n",
    "# Total number of rows in the DataFrame\n",
    "total_rows = len(df)\n",
    "print(\"Total number of rows:\", total_rows)\n",
    "\n",
    "####### seoarating features and labels ######################\n",
    "X = df.drop(columns=['Label'])  # Assuming 'label' is your target column\n",
    "y = df['Label']\n",
    "\n",
    "########## splitting it into test and train data set ###############\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "################ normalisation #################\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dd3b8f4-6ff3-425e-ab30-8fb92749206d",
   "metadata": {},
   "outputs": [],
   "source": [
    "############# Random Forest #######################\n",
    "\n",
    "rf_classifier = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the testing set\n",
    "y_pred = rf_classifier.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "specificity = conf_matrix[0, 0] / (conf_matrix[0, 0] + conf_matrix[0, 1])\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Specificity:\", specificity)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cc7289-d6d1-4960-b019-c9bf4203c8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "############# xgboost ############################\n",
    "xgb_classifier = XGBClassifier(random_state=42)\n",
    "\n",
    "# Train the model\n",
    "xgb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the testing set\n",
    "y_pred = xgb_classifier.predict(X_test)\n",
    "\n",
    "# Calculate evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "recall = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "specificity = conf_matrix[0, 0] / (conf_matrix[0, 0] + conf_matrix[0, 1])\n",
    "sensitivity = recall  # Sensitivity is the same as Recall\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall (Sensitivity):\", recall)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Specificity:\", specificity)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995b33b6-f2ac-437e-9f02-25fa22bf41c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "######## LOGISTICS REGRESSION ########\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn import svm\n",
    "\n",
    "file_path = 'your_output_file_features_with_label.csv'\n",
    "\n",
    "# Read CSV in chunks\n",
    "chunk_size = 100000  # Adjust chunk size as needed\n",
    "# Read CSV in chunks with low_memory=False\n",
    "chunks = pd.read_csv(file_path, chunksize=chunk_size, low_memory=False)\n",
    "\n",
    "# Initialize an empty DataFrame to store concatenated chunks\n",
    "df = pd.DataFrame()\n",
    "for chunk in chunks:\n",
    "    df = pd.concat([df, chunk])\n",
    "\n",
    "# Total number of rows in the DataFrame\n",
    "total_rows = len(df)\n",
    "print(\"Total number of rows:\", total_rows)\n",
    "\n",
    "####### seoarating features and labels ######################\n",
    "X = df.drop(columns=['Label'])  # Assuming 'label' is your target column\n",
    "y = df['Label']\n",
    "\n",
    "########## splitting it into test and train data set ###############\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "################ normalisation #################\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initializing Logistic Regression classifier\n",
    "clf = LogisticRegression()\n",
    "\n",
    "# Training the classifier\n",
    "clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Making predictions on the testing set\n",
    "y_pred = clf.predict(X_test_scaled)\n",
    "\n",
    "# Calculating evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "sensitivity = recall_score(y_test, y_pred)  # Also known as recall or true positive rate\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "specificity = tn / (tn + fp)  # True negative rate\n",
    "\n",
    "# Printing the evaluation metrics\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Sensitivity/Recall: {sensitivity:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"Specificity: {specificity:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa2357e-c093-4c3c-ad6f-926e17e4c0f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "######## DECISION TREE (BEST) ########\n",
    "# Initializing Decision Tree classifier\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "# Training the classifier\n",
    "clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Making predictions on the testing set\n",
    "y_pred = clf.predict(X_test_scaled)\n",
    "\n",
    "# Calculating evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "sensitivity = recall_score(y_test, y_pred)  # Also known as recall or true positive rate\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "specificity = tn / (tn + fp)  # True negative rate\n",
    "\n",
    "# Printing the evaluation metrics\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Sensitivity/Recall: {sensitivity:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"Specificity: {specificity:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4683462b-7eb4-4a71-9c90-f482e8b056a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "######## Gaussian Naive Bayes ########\n",
    "# Initializing Gaussian Naive Bayes classifier\n",
    "clf = GaussianNB()\n",
    "\n",
    "# Training the classifier\n",
    "clf.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Making predictions on the testing set\n",
    "y_pred = clf.predict(X_test_scaled)\n",
    "\n",
    "# Calculating evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "sensitivity = recall_score(y_test, y_pred)  # Also known as recall or true positive rate\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "tn, fp, fn, tp = cm.ravel()\n",
    "specificity = tn / (tn + fp)  # True negative rate\n",
    "\n",
    "# Printing the evaluation metrics\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Sensitivity/Recall: {sensitivity:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"Specificity: {specificity:.4f}\")\n",
    "print(\"Confusion Matrix:\")\n",
    "print(cm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb7ac53-b31d-4d3a-95a8-8291c8f16b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "######## ANN ########\n",
    "import pandas as pd\n",
    "from tensorflow import keras\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn import svm\n",
    "\n",
    "file_path = 'your_output_file_features_with_label.csv'\n",
    "# Read CSV in chunks\n",
    "chunk_size = 100000  # Adjust chunk size as needed\n",
    "# Read CSV in chunks with low_memory=False\n",
    "chunks = pd.read_csv(file_path, chunksize=chunk_size, low_memory=False)\n",
    "\n",
    "# Initialize an empty DataFrame to store concatenated chunks\n",
    "df = pd.DataFrame()\n",
    "for chunk in chunks:\n",
    "    df = pd.concat([df, chunk])\n",
    "\n",
    "# Total number of rows in the DataFrame\n",
    "total_rows = len(df)\n",
    "print(\"Total number of rows:\", total_rows)\n",
    "\n",
    "####### seoarating features and labels ######################\n",
    "X = df.drop(columns=['Label'])  # Assuming 'label' is your target column\n",
    "y = df['Label']\n",
    "\n",
    "########## splitting it into test and train data set ###############\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "################ normalisation #################\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Building the ANN model\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Dense(64, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compiling the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Training the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Predicting on the test set\n",
    "y_pred_proba = model.predict(X_test)\n",
    "y_pred = (y_pred_proba > 0.5).astype(int)\n",
    "\n",
    "# Calculating evaluation metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred)\n",
    "sensitivity = recall_score(y_test, y_pred)\n",
    "f1 = f1_score(y_test, y_pred)\n",
    "\n",
    "# Calculating specificity\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "specificity = tn / (tn + fp)\n",
    "\n",
    "# Confusion matrix\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Printing the results\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Sensitivity:\", sensitivity)\n",
    "print(\"F1 Score:\", f1)\n",
    "print(\"Specificity:\", specificity)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
